---
title: 'AI Fundamentals for Edge Devices (1/4)'
description: 'This module introduces the fundamental concepts of Edge Artificial Intelligence (Edge AI).'
tags:
  - Edge AI
  - Fundamentals
author: 'José Bagur'
hardware:
  - hardware/02.hero/boards/uno-r4-wifi
---

# AI Fundamentals for Edge Devices

This module introduces the fundamental concepts of Edge Artificial Intelligence (Edge AI), establishing the theoretical foundations necessary to understand how to implement machine learning solutions on resource-constrained devices such as microcontrollers and embedded systems.

## Introduction to Edge AI

### Machine Learning Fundamentals

Before exploring Edge AI, it is important to understand what a machine learning model is. Machine Learning is a branch of Artificial Intelligence (AI) that enables computer systems to learn patterns from data and make predictions or decisions without being explicitly programmed for each specific situation [1].

A machine learning model is a **mathematical representation of a particular event or process that captures the relationships between input and output variables** of that event. 

Let's consider **a practical example**: a machine learning model trained to detect anomalies in industrial *motor vibrations*. The process of creating a machine learning model involves **two fundamental phases**:

* **1.** **Training:** During this phase, the model analyzes a set of labeled data (input data with their corresponding correct outputs) and adjusts its internal parameters to minimize the error between its predictions and the actual measured values [2]. In our practical example it learns which vibration patterns correspond to normal operation and which indicate potential failures. This phase typically requires significant computational resources and is performed on high-capacity computers or in the cloud.

* **2.** **Inference:** Once trained, the model can process new, previously unseen data and generate predictions based on the learned patterns. This phase is considerably less demanding in terms of computational resources and is the one executed on edge devices. In the case of motor vibrations, the model will analyze new vibration measurements and classify them as normal or anomalous in real time, allowing motor operators to make preventive decisions.

### What is Edge AI?

Now that we understand how machine learning models work, we can explore where these models are executed. Traditionally, inference of complex models required powerful servers or cloud services. However, Edge AI is changing this dynamic.

Edge AI represents a paradigm shift in the implementation of Artificial Intelligence algorithms. Instead of sending data to remote servers for processing, Edge AI executes the inference phase of machine learning models directly on local devices, such as microcontrollers, smart sensors, or embedded systems [3].

The term "*edge*" refers to the physical location where data is generated and processed: **at the edge of the network, close to the source of information**.

Within this paradigm, an important specialization emerges: **TinyML** (Tiny Machine Learning). TinyML focuses specifically on running machine learning models on devices with extremely limited computational resources, such as microcontrollers with memory in the order of kilobytes (kB) and power consumption in the milliwatt (mW) range [4]. This technology enables incorporating artificial intelligence capabilities into devices that were previously considered too computationally constrained to run complex algorithms.

### Cloud Computing vs. Edge Computing

To better understand the value of Edge AI, it is important to distinguish between cloud computing and edge computing paradigms. Each has distinctive characteristics that make them suitable for different types of applications.

#### Cloud Computing

In the cloud computing model, data generated by sensors or devices is transmitted over the internet to remote servers with high processing capacity. These servers execute complex algorithms, store large volumes of information, and return results to the originating device.

The main characteristics of cloud computing are:

- Access to virtually unlimited computational resources
- Massive storage capacity
- Easy model updates and maintenance
- Dependence on internet connectivity
- Variable latency depending on network conditions
- Potential privacy vulnerabilities [5]

#### Edge Computing

Edge computing inverts the cloud computing model: processing occurs on the same device that captures the data or on a node close to it. Data does not need to travel to external servers; the local device executes the necessary algorithms to analyze the data and generates immediate responses.

The main characteristics of edge computing are:

- Local processing without dependence on internet connectivity
- Real-time responses with minimal latency
- Greater data privacy
- Limited computational resources
- Greater operational autonomy

#### Hybrid Architectures

It is important to note that **both computing paradigms are not mutually exclusive**. In many modern applications, it is common to find **hybrid architectures** where initial processing and critical real-time decisions occur at the edge, while model training, historical analysis, and remote supervision are performed in the cloud [6]. This combination allows leveraging the strengths of each paradigm according to the specific needs of the applications.

### Advantages of Edge AI

Let's look at the specific benefits that Edge AI provides, which make it a great fit for embedded applications where resources are limited but performance needs are high.

#### Low Latency

By eliminating the need to transmit data to remote servers and wait for responses from those servers, Edge AI enables response times in the order of milliseconds (ms). Recent research demonstrates that edge computing architectures can improve access latency by up to 30% compared to exclusively cloud-based solutions [7].

This characteristic is critical in applications where reaction speed determines system effectiveness. Some examples of such applications are as follows:

- Industrial process control
- Autonomous robotics
- Security and surveillance systems
- Autonomous vehicles
- Medical monitoring devices

#### Data Privacy and Security

Sensitive data remains on the local device and is never transmitted through external networks. This significantly reduces the attack surface for cybersecurity threats and facilitates compliance with data protection regulations [8].

In medical, industrial, or surveillance applications, this characteristic can be a fundamental requirement for compliance with regulations such as GDPR in Europe or HIPAA in the United States.

#### Offline Operation

Edge AI devices operate autonomously, regardless of the availability of an internet connection. This independence is essential for the following example cases:

- Deployments in remote locations (e.g., agriculture, mining, exploration)
- Industrial environments with limited or restricted internet connectivity
- Applications where service continuity cannot depend on external factors
- Emergency situations where network infrastructure may be compromised [9]

#### Energy Efficiency

Local processing eliminates the energy consumption associated with continuous data transmission over the internet. Additionally, modern microcontrollers optimized for Edge AI incorporate low-power modes that allow prolonged device operation using batteries.

A typical microcontroller requires energy in the milliwatt (mW) or microwatt (µW) range, consuming more than a thousand times less power than a standard computer [10]. This characteristic enables the following applications:

- Portable devices and wearables
- Sensors powered by batteries or alternative energy sources (e.g., solar energy)
- Massive Internet of Things (IoT) device deployments with low operational costs

#### Reduced Operational Costs

By minimizing data transfer and dependence on cloud services, Edge AI reduces costs associated with the following:

- Bandwidth and data transmission
- Storage on remote servers
- Processing on cloud infrastructure
- Maintenance of continuous connectivity

> According to ABI Research projections, 2.5 billion devices are expected to be shipped with specialized Edge AI chipsets by 2030, driven precisely by these economic and technical advantages [11].

## Hardware for Edge AI

Once the advantages of Edge AI are understood, a practical question arises: what hardware do we need to implement these solutions? In this section, we will explore the characteristics that a microcontroller must have to run machine learning models, and we will focus on the Arduino® UNO R4 WiFi board, the board we will use throughout this course.

### Microcontroller Architectures for AI

Not all microcontrollers are equally suitable for running machine learning models. The key characteristics that determine a microcontroller's capability for Edge AI include the following:

1. **Processing capacity:** The clock frequency and processor architecture determine how many operations can be performed per second. Arm Cortex-M processors are particularly popular in Edge AI applications due to their balance between performance and energy efficiency.

2. **Available memory:** Machine learning models require memory to store model parameters (Flash) and to perform intermediate calculations during inference (SRAM). The amount of available memory directly limits the size and complexity of models that can be executed.

3. **Specialized peripherals:** Some microcontrollers include digital signal processing (DSP) units or hardware accelerators specific to mathematical operations common in machine learning.

4. **Power consumption:** For battery-powered applications, consumption in active and sleep modes is critical.

### Arduino Hardware for Edge AI

Arduino offers various boards designed for Edge AI applications, each oriented toward different use cases. The following list presents the main available options:

- **Arduino Nicla Vision**: Designed for computer vision, it features an integrated 2 MP camera, dual-core STM32H747 processor, and multiple integrated sensors. This board is ideal for image and object recognition applications.
- **Arduino Nano 33 BLE Sense Rev2**: Compact board with multiple integrated environmental sensors (IMU, microphone, temperature, humidity, pressure, light). It is an excellent choice for audio classification, gesture detection, and environmental monitoring.
- **Arduino Portenta H7**: High-performance board with dual-core STM32H747 processor, oriented toward industrial applications requiring greater processing capacity.
- **Arduino UNO R4 WiFi**: Evolution of the iconic UNO family with a Renesas RA4M1 microcontroller, Wi-Fi/Bluetooth® connectivity, and capabilities for basic TinyML applications.

In this course, we will primarily work with the Arduino UNO R4 WiFi board due to its accessibility, familiarity for those who already know the Arduino platform, and its sufficient capabilities to understand Edge AI fundamentals.

#### Arduino UNO R4 WiFi: The Course Board

The Arduino UNO R4 WiFi represents the evolution of the UNO family, incorporating a significantly more powerful microcontroller than its predecessors while maintaining compatibility with the existing Arduino ecosystem. This combination makes it an excellent educational platform for Edge AI.

![UNO R4 wifi specifications](/_assets/uno-r4-callout.png)

The technical specifications of the UNO R4 WiFi are presented below [13]:

|  **Specification**  |           **Value**           |               **Notes**                |
| :-----------------: | :---------------------------: | :------------------------------------: |
|   Microcontroller   | Renesas RA4M1 (R7FA4M1AB3CFM) |          32-bit architecture           |
|      Processor      |    Arm Cortex-M4 @ 48 MHz     |     With floating-point unit (FPU)     |
|    Flash Memory     |            256 KB             |       Program and model storage        |
|     SRAM Memory     |             32 KB             |      Working memory for inference      |
|       EEPROM        |             8 KB              |        Persistent data storage         |
| Connectivity Module |           ESP32-S3            |          Secondary processor           |
|       Wi-Fi®        |    802.11 b/g/n (2.4 GHz)     |          For IoT connectivity          |
|      Bluetooth      |            LE 5.0             |        For local communication         |
|         ADC         |            14-bit             | Higher resolution than UNO R3 (10-bit) |
|         DAC         |            12-bit             |           True analog output           |
|    Digital Pins     |              14               |    Compatible with existing shields    |
|     Analog Pins     |               6               |             Sensor inputs              |
|     LED Matrix      |         12x8 red LEDs         |         For data visualization         |
|  Operating Voltage  |              5V               |    Compatible with standard sensors    |
|     Dimensions      |       68.85 x 53.34 mm        |        Standard UNO form factor        |

Although the UNO R4 WiFi has more limited resources than specialized boards like the Nicla Vision or Portenta H7, it also offers sufficient capabilities to implement Edge AI models in various scenarios. This board can run small classification models (up to approximately 50 KB), ideal for anomaly detection, vibration pattern classification, simple gesture recognition, and basic audio signal classification, among others.

## Real-World Edge AI Applications

Having explored both the theoretical concepts and available hardware, let's now see how Edge AI is applied in the real world. These examples illustrate the practical potential of the technologies we will learn to implement in this course.

### Industrial Use Cases

**Predictive maintenance:** Vibration sensors connected to industrial motors can detect anomalous patterns that precede mechanical failures. By processing data locally, the system can generate immediate alerts without depending on external connectivity. Arduino has developed specific examples for this use case using boards like the Nano R4 with external accelerometers [12].

**Visual quality control:** Cameras with local processing capability can inspect products on production lines, identifying defects in real time without the need to transmit images to external servers.

**Environmental monitoring:** Networks of sensors deployed in industrial facilities can detect gas leaks, temperature variations, or hazardous conditions, processing data locally to generate immediate responses.

### Commercial Use Cases

**Smart retail:** Vision systems can count people, analyze customer flows, and detect empty shelves without transmitting video to the cloud, preserving customer privacy.

**Precision agriculture:** Sensors in agricultural fields can analyze soil conditions, detect pests or plant diseases, and optimize irrigation, operating autonomously in locations without connectivity.

**Smart buildings:** HVAC systems can optimize energy consumption based on locally detected occupancy patterns, without the need for cloud infrastructure.

### Future Trends

The Edge AI field is evolving rapidly. Knowing these trends helps us anticipate where the technology is heading:

- **Specialized hardware**: New microcontrollers include specific accelerators for neural network operations, significantly improving performance without increasing power consumption.
- **More efficient models**: Research in neural network architectures optimized for embedded devices continues to produce smaller and more efficient models without sacrificing accuracy.
- **Simplified development tools**: <a href="https://www.edgeimpulse.com/" target="_blank">Platforms like Edge Impulse </a> are democratizing access to Edge AI, allowing developers without deep machine learning experience to create and deploy models.
- **Federated learning**: Techniques that allow improving models using data from multiple devices without centralizing information, preserving privacy while benefiting from collective learning.

## Summary

In this module, we have established the conceptual foundations necessary to understand Edge AI:

- A **machine learning model** learns patterns from data during training and uses them to make predictions during inference.
- **Edge AI** executes model inference directly on local devices, close to where data is generated.
- The **main advantages** of Edge AI include low latency, data privacy, offline operation, and energy efficiency.
- The **Arduino UNO R4 WiFi** board will be our development platform for the course; it offers a good balance between accessibility and Edge AI capabilities.
- **Real-world applications** of Edge AI range from industrial predictive maintenance to precision agriculture and smart buildings.

In the next module, we will delve deeper into machine learning fundamentals, exploring the types of algorithms most relevant to edge devices and the optimization techniques that make it possible to run models on microcontrollers.

## References

[1] IBM, "What is machine learning?" *IBM Think*, 2025. [Online]. Available: https://www.ibm.com/think/topics/machine-learning

[2] I. Goodfellow, Y. Bengio, and A. Courville, "Machine learning basics," in *Deep Learning*. Cambridge, MA, USA: MIT Press, 2016, ch. 5. [Online]. Available: https://www.deeplearningbook.org/contents/ml.html

[3] C. R. Banbury et al., "Machine learning for embedded systems: A case study," *arXiv preprint arXiv:2303.13569*, 2023.

[4] P. Warden and D. Situnayake, *TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers*. Sebastopol, CA, USA: O'Reilly Media, 2019.

[5] T. Sampath, A. Dutt, V. Veeraiah, B. Aishwarya, K. Lal, and D. Kapila, "Analyzing the effect of edge computing on real-time data processing and latency reduction," in *Proc. 10th IEEE Uttar Pradesh Section Int. Conf. Electr., Electron. Comput. Eng. (UPCON)*, Gautam Buddha Nagar, India, 2023, pp. 623–627, doi: 10.1109/UPCON59197.2023.10434652.

[6] Y. Abadade, A. Temouden, H. Bamoumen, N. Benamar, Y. Chtouki, and A. S. Hafid, "A comprehensive survey on TinyML," *IEEE Access*, vol. 11, pp. 96892–96922, 2023, doi: 10.1109/ACCESS.2023.3294111.

[7] F. Breitbach, L. Trestian, P. Bujari, P. Bellavista, and G. Haring, "(How much) can edge computing change network latency?" in *Proc. IFIP Netw. Conf.*, Espoo, Finland, 2021, pp. 1–9, doi: 10.23919/IFIPNetworking52078.2021.9472790.

[8] A. Garcia, P. Serrano, D. Urda, J. J. Rodriguez, and C. Garcia-Osorio, "Embedded AI and TinyML: A practical analysis of workflows and libraries," in *Distributed Computing and Artificial Intelligence (DCAI 2024)*, vol. 1259, Lecture Notes in Networks and Systems. Cham, Switzerland: Springer, 2025, pp. 1–10.

[9] E. Lear et al., "Internet of Things (IoT) edge challenges and functions," RFC 9556, Internet Research Task Force (IRTF), Apr. 2024. [Online]. Available: https://datatracker.ietf.org/doc/rfc9556/

[10] AIMultiple Research, "TinyML: Machine learning at the edge," 2024. [Online]. Available: https://research.aimultiple.com/tinyml/

[11] R. Kallimani et al., "TinyML: Enabling of inference deep learning models on ultra-low-power IoT edge devices for AI applications," *Micromachines*, vol. 13, no. 6, p. 851, May 2022, doi: 10.3390/mi13060851.

[12] Arduino Product Experience Team, "Motor anomaly detection with the Nano R4," Arduino Application Notes, 2025. [Online]. Available: https://docs.arduino.cc/tutorials/nano-r4/motor-anomaly-detection/

[13] Arduino, "UNO R4 WiFi," Arduino Documentation, 2024. [Online]. Available: https://docs.arduino.cc/hardware/uno-r4-wifi/